{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68fd682a-4d77-4109-adfc-4dfabe5a6277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59e2aff890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch,torchvision\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    RobustScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    OneHotEncoder,\n",
    "    LabelEncoder,\n",
    "    Normalizer,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,VotingRegressor,BaggingRegressor,RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from catboost import CatBoost,CatBoostRegressor\n",
    "from xgboost import XGBRegressor,XGBRFRegressor\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score,precision_score,f1_score,recall_score\n",
    "import pickle\n",
    "import wandb\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "PROJECT_NAME = 'House-Prices-Advanced-Regression-Techniques-V7'\n",
    "device = 'cuda'\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "torch.manual_seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0fc8e6-05ef-4c53-adc2-e288c421f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(model,name):\n",
    "    data = pd.read_csv('./data/test.csv')\n",
    "    ids = data['Id']\n",
    "    for one_hot_encoding_col in one_hot_encoding:\n",
    "        data,idx,labels_and_int_index,new_data = object_to_int(data,one_hot_encoding_col)\n",
    "    for num_of_samples,col,dtype in zip(data.isna().sum(),data.columns,data.dtypes):\n",
    "        if dtype == 'object':\n",
    "            pass\n",
    "        else:\n",
    "            if num_of_samples > 0:\n",
    "                data[col].fillna(data[col].median(),inplace=True)\n",
    "    \n",
    "    preds = model.predict(data)\n",
    "    df = pd.DataFrame({'Id':ids,'SalePrice':preds})\n",
    "    df.to_csv(f'./submisssions/{name}.csv',index=False)\n",
    "    return df\n",
    "def validate(model,X,y,val=False):\n",
    "    preds = model.predict(X)\n",
    "    try:\n",
    "        if val:\n",
    "            result = {\n",
    "                'MAE':mean_absolute_error(y_pred=preds,y_true=y),\n",
    "                'MSE':mean_squared_error(y_pred=preds,y_true=y),\n",
    "                'Accuracy':model.score(X,y),\n",
    "            }\n",
    "        else:\n",
    "            result = {\n",
    "                'Val MAE':mean_absolute_error(y_pred=preds,y_true=y),\n",
    "                'Val MSE':mean_squared_error(y_pred=preds,y_true=y),\n",
    "                'Val Accuracy':model.score(X,y),\n",
    "            }\n",
    "    except:\n",
    "        if val:\n",
    "            result = {\n",
    "                'MAE':mean_absolute_error(y_pred=preds,y_true=y),\n",
    "                'MSE':mean_squared_error(y_pred=preds,y_true=y),\n",
    "            }\n",
    "        else:\n",
    "            result = {\n",
    "                'Val MAE':mean_absolute_error(y_pred=preds,y_true=y),\n",
    "                'Val MSE':mean_squared_error(y_pred=preds,y_true=y),\n",
    "            }\n",
    "    return result\n",
    "def train(model,X_train,X_test,y_train,y_test,name):\n",
    "    wandb.init(project=PROJECT_NAME,name=name)\n",
    "    model.fit(X_train,y_train)\n",
    "    wandb.log(validate(model,X_train,y_train))\n",
    "    wandb.log(validate(model,X_test,y_test,True))\n",
    "    wandb.sklearn.plot_regressor(model, X_train, X_test, y_train, y_test,  model_name=name)\n",
    "    pickle.dump(model,open(f'./models/model-{name}.pkl','wb'))\n",
    "    make_submission(model,name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561ecab3-849c-460b-860b-75d83cf8258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56c0d26-ad8e-44ce-93a4-0c48e9dff498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613daf38-4981-4c03-a742-42d4679ba0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6396eb5-229e-4b75-b859-9ac0fd734f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name,dtype in zip(data.columns,data.dtypes):\n",
    "    if dtype == 'object':\n",
    "        one_hot_encoding.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d343e0-3094-461e-b033-cfcb52c29d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656e317c-875a-47f3-b47a-286eba083ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding_data = data[one_hot_encoding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4826cede-f25a-43fb-8c74-f60f5bc64ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_int(data,col):\n",
    "    data_col = data[col].to_dict()\n",
    "    idx = -1\n",
    "    labels_and_int_index = {}\n",
    "    for data_col_vals in data_col.values():\n",
    "        if data_col_vals not in labels_and_int_index.keys():\n",
    "            idx += 1\n",
    "            labels_and_int_index[data_col_vals] = idx\n",
    "    new_data = []\n",
    "    for data_col_vals in data_col.values():\n",
    "        new_data.append(labels_and_int_index[data_col_vals])\n",
    "    data[col] = new_data\n",
    "    return data,idx,labels_and_int_index,new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fabd03-1014-468b-8937-0aa9ff4e6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_and_int_indexs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd7a3d8-06c7-4e05-8823-4a4681e50a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for one_hot_encoding_col in one_hot_encoding:\n",
    "    data,idx,labels_and_int_index,new_data = object_to_int(data,one_hot_encoding_col)\n",
    "    labels_and_int_index[one_hot_encoding_col] = labels_and_int_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c39e56d3-8dee-492c-9515-43584133b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_of_samples,col,dtype in zip(data.isna().sum(),data.columns,data.dtypes):\n",
    "    if dtype == 'object':\n",
    "        pass\n",
    "    else:\n",
    "        if num_of_samples > 0:\n",
    "            data[col].fillna(data[col].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95bcea85-7ac1-445b-a77a-760ace40c3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142ac360-e44f-4477-b8b5-19ee9de57643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0   1          60         0         65.0     8450       0      0         0   \n",
       "1   2          20         0         80.0     9600       0      0         0   \n",
       "2   3          60         0         68.0    11250       0      0         1   \n",
       "3   4          70         0         60.0     9550       0      0         1   \n",
       "4   5          60         0         84.0    14260       0      0         1   \n",
       "\n",
       "   LandContour  Utilities  ...  PoolArea  PoolQC  Fence  MiscFeature  MiscVal  \\\n",
       "0            0          0  ...         0       0      0            0        0   \n",
       "1            0          0  ...         0       0      0            0        0   \n",
       "2            0          0  ...         0       0      0            0        0   \n",
       "3            0          0  ...         0       0      0            0        0   \n",
       "4            0          0  ...         0       0      0            0        0   \n",
       "\n",
       "   MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0       2    2008         0              0     208500  \n",
       "1       5    2007         0              0     181500  \n",
       "2       9    2008         0              0     223500  \n",
       "3       2    2006         0              1     140000  \n",
       "4      12    2008         0              0     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a521ee8-8bfc-499b-bc63-9ca89c2c0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('SalePrice',axis=1)\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "463084d5-0917-483a-bd5f-7106525934d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e16f87c-1ab2-4b21-b380-b3286291000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GradientBoostingRegressor()\n",
    "# train(model,X_train,X_test,y_train,y_test,f'First test GradientBoostingRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92322d8-ff78-4ceb-a6ee-a283aadca2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_old = X_train.copy()\n",
    "X_test_old = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82fd513e-98bd-4872-b837-f4ea5d1cc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = [\n",
    "#         StandardScaler,\n",
    "#     RobustScaler,\n",
    "#     MinMaxScaler,\n",
    "#     MaxAbsScaler,\n",
    "#     Normalizer,]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0ba3f19-3ee8-4869-b4b7-ffb5c8d9fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler = 1.2\n",
    "# RobustScaler = 1.2\n",
    "# MinMaxScaler = 1.1\n",
    "# MaxAbsScaler = 1.2\n",
    "# Normalizer = 0.47\n",
    "# Normal = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a036aba-6a6e-40b4-9b20-56625ffd699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre in pres:\n",
    "#     X_train = X_train_old.copy()\n",
    "#     X_test = X_test_old.copy()\n",
    "#     mct = make_column_transformer(\n",
    "#         (pre(),X.columns)\n",
    "#     )\n",
    "#     X_train = mct.fit_transform(X_train)\n",
    "#     X_test = mct.transform(X_test)\n",
    "#     model = RandomForestRegressor()\n",
    "#     train(model,X_train,X_test,y_train,y_test,f'Pre Proccessing - {pre()}')\n",
    "# mct = make_column_transformer(\n",
    "#     (pre(),X.columns)\n",
    "# )\n",
    "# X_train = mct.fit_transform(X_train)\n",
    "# X_test = mct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d1439f-6538-47cf-91ca-b42136bd3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "#     ['KNeighborsRegressor',KNeighborsRegressor],\n",
    "#     ['LogisticRegression',LogisticRegression],\n",
    "#     ['LogisticRegressionCV',LogisticRegressionCV],\n",
    "#     ['DecisionTreeRegressor',DecisionTreeRegressor],\n",
    "#     ['GradientBoostingRegressor',GradientBoostingRegressor],\n",
    "#     ['AdaBoostRegressor',AdaBoostRegressor],\n",
    "#     ['RandomForestRegressor',RandomForestRegressor],\n",
    "#     ['BaggingRegressor',BaggingRegressor],\n",
    "#     ['GaussianNB',GaussianNB],\n",
    "#     ['ExtraTreesRegressor',ExtraTreesRegressor],\n",
    "#     ['CatBoost',CatBoost],\n",
    "#     ['CatBoostRegressor',CatBoostRegressor],\n",
    "#     ['XGBRegressor',XGBRegressor],\n",
    "#     ['XGBRFRegressor',XGBRFRegressor],\n",
    "#     ['ExtraTreesRegressor',ExtraTreesRegressor],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "098188c6-66ed-420e-86f4-b977c372ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "#     train(model[1](),X_train,X_test,y_train,y_test,model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40affcbb-f51f-46f9-a1d9-0b1922ede2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forrest Regressor = 0.15\n",
    "# Ada Boost Regressor = 0.21\n",
    "# Decision Tree Regressor = 0.23\n",
    "# Gradient Boost Regressor = 0.14\n",
    "# BaggingRegressor = 0.16\n",
    "# ExtraTreesRegressor = 0.16\n",
    "# CatBoost = 0.15\n",
    "# CatBoostRegressor = 0.16\n",
    "# XGBRegressor = 0.16\n",
    "# XGBRFRegressor = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdef4c-10e7-4908-aef8-b2deda71a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranuga-d\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">GirdSearch</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/House-Prices-Advanced-Regression-Techniques-V7\" target=\"_blank\">https://wandb.ai/ranuga-d/House-Prices-Advanced-Regression-Techniques-V7</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/House-Prices-Advanced-Regression-Techniques-V7/runs/29im35lj\" target=\"_blank\">https://wandb.ai/ranuga-d/House-Prices-Advanced-Regression-Techniques-V7/runs/29im35lj</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/Sklearn-PyTorch/House-Prices-Advanced-Regression-Techniques-V7/wandb/run-20210823_233849-29im35lj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 720 candidates, totalling 1440 fits\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=100;, score=0.852 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=100;, score=0.913 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=125;, score=0.853 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=125;, score=0.919 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=250;, score=0.855 total time=   0.6s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=250;, score=0.918 total time=   0.7s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=500;, score=0.855 total time=   1.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=500;, score=0.920 total time=   1.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=100;, score=0.854 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=100;, score=0.899 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=125;, score=0.860 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=125;, score=0.894 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=250;, score=0.865 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=250;, score=0.899 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=500;, score=0.848 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=500;, score=0.908 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=100;, score=0.848 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=100;, score=0.893 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=125;, score=0.855 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=125;, score=0.908 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=250;, score=0.870 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=250;, score=0.907 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=500;, score=0.858 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=500;, score=0.911 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=100;, score=0.835 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=100;, score=0.861 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=125;, score=0.835 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=125;, score=0.871 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=250;, score=0.843 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=250;, score=0.897 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=500;, score=0.850 total time=   1.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=500;, score=0.891 total time=   1.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=100;, score=0.872 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=125;, score=0.844 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=125;, score=0.879 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=250;, score=0.844 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=250;, score=0.897 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=500;, score=0.834 total time=   0.7s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=500;, score=0.903 total time=   0.7s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=100;, score=0.838 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=100;, score=0.854 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=125;, score=0.844 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=125;, score=0.869 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=250;, score=0.837 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=250;, score=0.896 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=500;, score=0.838 total time=   0.7s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=500;, score=0.901 total time=   0.7s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=100;, score=0.837 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=100;, score=0.911 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=125;, score=0.838 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=125;, score=0.911 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=250;, score=0.833 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=250;, score=0.914 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=500;, score=0.831 total time=   2.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=500;, score=0.918 total time=   2.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=100;, score=0.857 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=100;, score=0.891 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=125;, score=0.847 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=125;, score=0.899 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=250;, score=0.846 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=250;, score=0.904 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=500;, score=0.851 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=500;, score=0.906 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=100;, score=0.847 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=100;, score=0.891 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=125;, score=0.853 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=125;, score=0.898 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=250;, score=0.855 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=250;, score=0.906 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=500;, score=0.852 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=500;, score=0.912 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=100;, score=0.699 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=100;, score=0.803 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=125;, score=0.727 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=125;, score=0.826 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=250;, score=0.705 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=250;, score=0.820 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=500;, score=0.718 total time=   1.7s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=500;, score=0.843 total time=   1.7s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=100;, score=0.726 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=100;, score=0.831 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.746 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.846 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.766 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.856 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.780 total time=   0.7s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.870 total time=   0.7s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=100;, score=0.704 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=100;, score=0.839 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=125;, score=0.755 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=125;, score=0.848 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=250;, score=0.758 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=250;, score=0.845 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=500;, score=0.773 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=500;, score=0.875 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=100;, score=0.646 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=100;, score=0.678 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=125;, score=0.701 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=125;, score=0.745 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=250;, score=0.812 total time=   0.7s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=250;, score=0.863 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=500;, score=0.848 total time=   1.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=500;, score=0.905 total time=   1.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=100;, score=0.607 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=100;, score=0.608 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=125;, score=0.673 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=125;, score=0.677 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=250;, score=0.809 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=250;, score=0.840 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=500;, score=0.856 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=500;, score=0.896 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=100;, score=0.602 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=100;, score=0.595 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=125;, score=0.664 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=125;, score=0.651 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=250;, score=0.803 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=250;, score=0.825 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=500;, score=0.857 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=500;, score=0.892 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=100;, score=0.506 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=100;, score=0.418 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=125;, score=0.568 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=125;, score=0.503 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=250;, score=0.712 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=250;, score=0.699 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=500;, score=0.807 total time=   1.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=500;, score=0.826 total time=   1.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=100;, score=0.467 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=100;, score=0.373 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=125;, score=0.526 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=125;, score=0.449 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=250;, score=0.693 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=250;, score=0.671 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=500;, score=0.799 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=500;, score=0.817 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=100;, score=0.445 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=100;, score=0.364 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=125;, score=0.501 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=125;, score=0.436 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=250;, score=0.685 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=250;, score=0.657 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=500;, score=0.794 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=500;, score=0.804 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=100;, score=0.603 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=100;, score=0.597 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=125;, score=0.657 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=125;, score=0.666 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=250;, score=0.780 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=250;, score=0.815 total time=   1.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=500;, score=0.835 total time=   2.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=500;, score=0.888 total time=   2.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=100;, score=0.564 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=100;, score=0.532 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=125;, score=0.623 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=125;, score=0.612 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=250;, score=0.768 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=250;, score=0.779 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=500;, score=0.841 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=500;, score=0.875 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=100;, score=0.558 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=100;, score=0.520 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=125;, score=0.616 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=125;, score=0.594 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=250;, score=0.759 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=250;, score=0.774 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=500;, score=0.834 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=500;, score=0.868 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=100;, score=-0.649 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=100;, score=-0.113 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=125;, score=-0.424 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=125;, score=0.030 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=250;, score=0.277 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=250;, score=0.415 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=500;, score=0.634 total time=   1.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=500;, score=0.716 total time=   1.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.642 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.122 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=125;, score=-0.429 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.055 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.249 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.480 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.644 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.767 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=100;, score=-0.662 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=100;, score=-0.082 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=125;, score=-0.428 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=125;, score=0.086 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=250;, score=0.261 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=250;, score=0.510 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=500;, score=0.640 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=500;, score=0.777 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=100;, score=0.117 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=100;, score=0.121 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=125;, score=0.146 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=125;, score=0.151 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=250;, score=0.269 total time=   0.6s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=250;, score=0.278 total time=   0.6s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=500;, score=0.445 total time=   1.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=500;, score=0.467 total time=   1.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=100;, score=0.096 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=100;, score=0.091 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.119 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.115 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.232 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.223 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.403 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.397 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=100;, score=0.091 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=100;, score=0.087 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=125;, score=0.113 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=125;, score=0.110 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=250;, score=0.220 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=250;, score=0.216 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=500;, score=0.387 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=500;, score=0.379 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=100;, score=0.065 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=100;, score=-0.046 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=125;, score=0.083 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=125;, score=-0.030 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=250;, score=0.164 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=250;, score=0.053 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=500;, score=0.296 total time=   1.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=500;, score=0.196 total time=   1.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=100;, score=0.057 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.042 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=125;, score=0.073 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.027 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.146 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.054 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.273 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.183 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=100;, score=0.056 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=100;, score=-0.044 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=125;, score=0.070 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=125;, score=-0.027 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=250;, score=0.145 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=250;, score=0.049 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=500;, score=0.272 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=500;, score=0.176 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=100;, score=0.112 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=100;, score=0.015 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=125;, score=0.140 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=125;, score=0.044 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=250;, score=0.258 total time=   1.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=250;, score=0.172 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=500;, score=0.425 total time=   2.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=500;, score=0.360 total time=   2.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=100;, score=0.091 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.005 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.110 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.019 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.212 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.134 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.374 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.310 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=100;, score=0.083 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=100;, score=-0.014 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=125;, score=0.104 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=125;, score=0.012 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=250;, score=0.203 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=250;, score=0.119 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=500;, score=0.361 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=500;, score=0.289 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=100;, score=-1.883 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=100;, score=-0.932 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=125;, score=-1.830 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=125;, score=-0.895 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=250;, score=-1.603 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=250;, score=-0.727 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.225 total time=   2.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=500;, score=-0.460 total time=   1.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.887 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.945 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.841 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-0.904 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.597 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-0.737 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.214 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-0.474 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=100;, score=-1.894 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=100;, score=-0.944 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=125;, score=-1.843 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=125;, score=-0.911 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=250;, score=-1.590 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=250;, score=-0.750 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=500;, score=-1.207 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=500;, score=-0.473 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=100;, score=0.002 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=100;, score=0.003 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=125;, score=0.005 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=125;, score=0.007 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=250;, score=0.022 total time=   0.7s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=250;, score=0.025 total time=   0.7s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=500;, score=0.056 total time=   1.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=500;, score=0.060 total time=   1.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.002 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.002 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.016 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.015 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.044 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.042 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=125;, score=0.001 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=125;, score=0.001 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=250;, score=0.014 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=250;, score=0.014 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=500;, score=0.041 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=500;, score=0.039 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=100;, score=-0.005 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=100;, score=-0.110 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=125;, score=-0.003 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=125;, score=-0.109 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=250;, score=0.008 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=250;, score=-0.100 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=500;, score=0.027 total time=   1.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=500;, score=-0.080 total time=   1.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.006 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.110 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.004 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.108 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.006 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=250;, score=-0.098 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.024 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=500;, score=-0.079 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=100;, score=-0.006 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=100;, score=-0.110 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=125;, score=-0.004 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=125;, score=-0.108 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=250;, score=0.005 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=250;, score=-0.099 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=500;, score=0.023 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=500;, score=-0.080 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=100;, score=0.001 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=100;, score=-0.103 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=125;, score=0.004 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=125;, score=-0.099 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=250;, score=0.021 total time=   1.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=250;, score=-0.082 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=500;, score=0.053 total time=   2.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=500;, score=-0.048 total time=   2.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.002 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.106 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.001 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=125;, score=-0.103 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.014 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=250;, score=-0.088 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.040 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=500;, score=-0.060 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=100;, score=-0.003 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=100;, score=-0.107 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=125;, score=-0.000 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=125;, score=-0.104 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=250;, score=0.012 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=250;, score=-0.090 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=500;, score=0.037 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=500;, score=-0.064 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=100;, score=-2.095 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=100;, score=-1.085 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=125;, score=-2.089 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=125;, score=-1.080 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=250;, score=-2.057 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=250;, score=-1.057 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.997 total time=   1.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.013 total time=   1.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-2.096 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.086 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-2.090 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.082 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-2.062 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.061 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-2.003 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.020 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=100;, score=-2.097 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=100;, score=-1.087 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=125;, score=-2.092 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=125;, score=-1.083 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=250;, score=-2.062 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=250;, score=-1.062 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=500;, score=-2.005 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=500;, score=-1.022 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=100;, score=-0.011 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=100;, score=-0.011 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=125;, score=-0.010 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=125;, score=-0.010 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=250;, score=-0.009 total time=   0.6s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=250;, score=-0.008 total time=   0.6s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=500;, score=-0.005 total time=   1.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=500;, score=-0.005 total time=   1.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=125;, score=-0.011 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=125;, score=-0.011 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=500;, score=-0.006 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=500;, score=-0.006 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=125;, score=-0.011 total time=   0.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=125;, score=-0.011 total time=   0.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=250;, score=-0.010 total time=   0.1s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=500;, score=-0.007 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=500;, score=-0.007 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=100;, score=-0.012 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=100;, score=-0.117 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=125;, score=-0.012 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=125;, score=-0.117 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=250;, score=-0.011 total time=   0.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=250;, score=-0.116 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=500;, score=-0.009 total time=   1.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=500;, score=-0.114 total time=   1.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=250;, score=-0.011 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=250;, score=-0.116 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=500;, score=-0.009 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=500;, score=-0.114 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=125;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=125;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=250;, score=-0.011 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=250;, score=-0.116 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=500;, score=-0.009 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=500;, score=-0.114 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=100;, score=-0.012 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=100;, score=-0.116 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=125;, score=-0.011 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=125;, score=-0.116 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=250;, score=-0.009 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=250;, score=-0.114 total time=   1.1s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=500;, score=-0.006 total time=   2.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=500;, score=-0.110 total time=   2.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=125;, score=-0.012 total time=   0.3s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=125;, score=-0.116 total time=   0.3s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=250;, score=-0.010 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=250;, score=-0.115 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=500;, score=-0.007 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=500;, score=-0.112 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=125;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=125;, score=-0.116 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=250;, score=-0.010 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=250;, score=-0.115 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=500;, score=-0.008 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=500;, score=-0.112 total time=   1.0s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=100;, score=-2.118 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=100;, score=-1.102 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=125;, score=-2.117 total time=   0.5s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=125;, score=-1.101 total time=   0.5s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=250;, score=-2.114 total time=   1.0s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=250;, score=-1.099 total time=   0.9s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=500;, score=-2.108 total time=   1.9s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=500;, score=-1.094 total time=   1.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=100;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=125;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=250;, score=-2.115 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.099 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=500;, score=-2.109 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.095 total time=   0.8s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=100;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=100;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=125;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=125;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=250;, score=-2.115 total time=   0.4s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=250;, score=-1.100 total time=   0.4s\n",
      "[CV 1/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=500;, score=-2.109 total time=   0.8s\n",
      "[CV 2/2] END criterion=friedman_mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=500;, score=-1.095 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=100;, score=0.852 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=100;, score=0.913 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=125;, score=0.853 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=125;, score=0.914 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=250;, score=0.856 total time=   0.6s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=250;, score=0.919 total time=   0.6s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=500;, score=0.854 total time=   1.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=500;, score=0.922 total time=   1.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=100;, score=0.855 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=100;, score=0.907 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=125;, score=0.861 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=125;, score=0.918 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=250;, score=0.864 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=250;, score=0.904 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=500;, score=0.857 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=500;, score=0.915 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=100;, score=0.858 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=100;, score=0.900 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=125;, score=0.845 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=125;, score=0.910 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=250;, score=0.859 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=250;, score=0.902 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=500;, score=0.860 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=500;, score=0.914 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=100;, score=0.832 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=100;, score=0.868 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=125;, score=0.836 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=125;, score=0.886 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=250;, score=0.838 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=250;, score=0.889 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=500;, score=0.846 total time=   1.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=500;, score=0.901 total time=   1.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=100;, score=0.834 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=100;, score=0.880 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=125;, score=0.840 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=125;, score=0.875 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=250;, score=0.834 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=250;, score=0.888 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=500;, score=0.842 total time=   0.7s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=500;, score=0.911 total time=   0.7s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=100;, score=0.833 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=100;, score=0.866 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=125;, score=0.839 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=125;, score=0.869 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=250;, score=0.847 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=250;, score=0.894 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=500;, score=0.843 total time=   0.7s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=500;, score=0.902 total time=   0.7s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=100;, score=0.842 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=100;, score=0.908 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=125;, score=0.837 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=125;, score=0.913 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=250;, score=0.837 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=250;, score=0.919 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=500;, score=0.828 total time=   2.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=500;, score=0.917 total time=   2.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=100;, score=0.846 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=100;, score=0.898 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=125;, score=0.842 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=125;, score=0.908 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=250;, score=0.853 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=250;, score=0.894 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=500;, score=0.858 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=500;, score=0.911 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=100;, score=0.850 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=100;, score=0.897 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=125;, score=0.851 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=125;, score=0.899 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=250;, score=0.865 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=250;, score=0.900 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=500;, score=0.864 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=500;, score=0.908 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=100;, score=0.701 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=100;, score=0.811 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=125;, score=0.697 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=125;, score=0.818 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=250;, score=0.723 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=250;, score=0.825 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=500;, score=0.758 total time=   1.7s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=500;, score=0.818 total time=   1.7s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=100;, score=0.726 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=100;, score=0.826 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.743 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.833 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.797 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.860 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.803 total time=   0.7s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.856 total time=   0.7s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=100;, score=0.722 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=100;, score=0.820 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=125;, score=0.749 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=125;, score=0.843 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=250;, score=0.759 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=250;, score=0.876 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=500;, score=0.783 total time=   0.7s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=500;, score=0.866 total time=   0.7s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=100;, score=0.647 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=100;, score=0.681 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=125;, score=0.702 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=125;, score=0.740 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=250;, score=0.812 total time=   0.6s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=250;, score=0.862 total time=   0.6s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=500;, score=0.848 total time=   1.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=500;, score=0.905 total time=   1.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=100;, score=0.607 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=100;, score=0.613 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=125;, score=0.671 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=125;, score=0.676 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=250;, score=0.807 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=250;, score=0.834 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=500;, score=0.852 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=500;, score=0.896 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=100;, score=0.596 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=100;, score=0.591 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=125;, score=0.657 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=125;, score=0.659 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=250;, score=0.798 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=250;, score=0.816 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=500;, score=0.850 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=500;, score=0.892 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=100;, score=0.506 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=100;, score=0.427 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=125;, score=0.569 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=125;, score=0.502 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=250;, score=0.711 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=250;, score=0.703 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=500;, score=0.807 total time=   1.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=500;, score=0.829 total time=   1.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=100;, score=0.445 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=100;, score=0.376 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=125;, score=0.533 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=125;, score=0.444 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=250;, score=0.694 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=250;, score=0.682 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=500;, score=0.797 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=500;, score=0.820 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=100;, score=0.449 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=100;, score=0.359 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=125;, score=0.509 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=125;, score=0.432 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=250;, score=0.687 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=250;, score=0.665 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=500;, score=0.797 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=500;, score=0.811 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=100;, score=0.603 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=100;, score=0.597 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=125;, score=0.657 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=125;, score=0.666 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=250;, score=0.780 total time=   1.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=250;, score=0.816 total time=   1.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=500;, score=0.836 total time=   2.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=500;, score=0.886 total time=   2.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=100;, score=0.568 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=100;, score=0.535 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=125;, score=0.627 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=125;, score=0.611 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=250;, score=0.773 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=250;, score=0.781 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=500;, score=0.838 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=500;, score=0.872 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=100;, score=0.558 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=100;, score=0.519 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=125;, score=0.616 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=125;, score=0.588 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=250;, score=0.755 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=250;, score=0.772 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=500;, score=0.835 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=500;, score=0.866 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=100;, score=-0.617 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=100;, score=-0.102 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=125;, score=-0.418 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=125;, score=0.025 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=250;, score=0.280 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=250;, score=0.448 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=500;, score=0.621 total time=   1.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=500;, score=0.716 total time=   1.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.681 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.054 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=125;, score=-0.441 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.019 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.258 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.492 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.642 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.767 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=100;, score=-0.689 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=100;, score=-0.063 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=125;, score=-0.422 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=125;, score=0.041 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=250;, score=0.285 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=250;, score=0.506 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=500;, score=0.647 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=500;, score=0.781 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=100;, score=0.117 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=100;, score=0.122 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=125;, score=0.146 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=125;, score=0.151 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=250;, score=0.269 total time=   0.6s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=250;, score=0.277 total time=   0.6s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=500;, score=0.445 total time=   1.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=500;, score=0.466 total time=   1.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=100;, score=0.095 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=100;, score=0.092 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.119 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.116 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.230 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.224 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.402 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.396 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=100;, score=0.090 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=100;, score=0.089 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=125;, score=0.114 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=125;, score=0.108 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=250;, score=0.220 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=250;, score=0.213 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=500;, score=0.387 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=500;, score=0.381 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=100;, score=0.065 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=100;, score=-0.046 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=125;, score=0.083 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=125;, score=-0.030 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=250;, score=0.164 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=250;, score=0.053 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=500;, score=0.296 total time=   1.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=500;, score=0.197 total time=   1.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=100;, score=0.058 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.044 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=125;, score=0.073 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.027 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.150 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.053 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.277 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.183 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=100;, score=0.057 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=100;, score=-0.047 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=125;, score=0.072 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=125;, score=-0.028 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=250;, score=0.144 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=250;, score=0.048 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=500;, score=0.267 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=500;, score=0.177 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=100;, score=0.112 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=100;, score=0.015 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=125;, score=0.140 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=125;, score=0.044 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=250;, score=0.258 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=250;, score=0.172 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=500;, score=0.425 total time=   2.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=500;, score=0.360 total time=   2.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=100;, score=0.091 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.008 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.113 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.019 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.217 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.133 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.376 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.310 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=100;, score=0.084 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=100;, score=-0.011 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=125;, score=0.107 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=125;, score=0.013 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=250;, score=0.207 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=250;, score=0.125 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=500;, score=0.360 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=500;, score=0.290 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=100;, score=-1.883 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=100;, score=-0.931 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=125;, score=-1.830 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=125;, score=-0.894 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=250;, score=-1.603 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=250;, score=-0.725 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.224 total time=   1.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=500;, score=-0.456 total time=   1.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.890 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.941 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.833 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-0.910 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.596 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-0.736 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.223 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-0.480 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=100;, score=-1.898 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=100;, score=-0.947 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=125;, score=-1.838 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=125;, score=-0.910 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=250;, score=-1.593 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=250;, score=-0.753 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=500;, score=-1.200 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=500;, score=-0.475 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=100;, score=0.002 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=100;, score=0.003 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=125;, score=0.005 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=125;, score=0.007 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=250;, score=0.022 total time=   0.6s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=250;, score=0.025 total time=   0.6s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=500;, score=0.056 total time=   1.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=500;, score=0.059 total time=   1.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.002 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.002 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.016 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.015 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.044 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.042 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=100;, score=-0.001 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=100;, score=-0.002 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=125;, score=0.001 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=125;, score=0.001 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=250;, score=0.015 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=250;, score=0.014 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=500;, score=0.040 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=500;, score=0.040 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=100;, score=-0.005 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=100;, score=-0.110 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=125;, score=-0.003 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=125;, score=-0.109 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=250;, score=0.008 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=250;, score=-0.100 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=500;, score=0.027 total time=   1.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=500;, score=-0.080 total time=   1.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.005 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.110 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.004 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.108 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.005 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=250;, score=-0.098 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.023 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=sqrt, n_estimators=500;, score=-0.079 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=100;, score=-0.006 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=100;, score=-0.110 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=125;, score=-0.004 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=125;, score=-0.108 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=250;, score=0.005 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=250;, score=-0.098 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=500;, score=0.023 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=lad, max_features=log2, n_estimators=500;, score=-0.080 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=100;, score=0.001 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=100;, score=-0.103 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=125;, score=0.004 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=125;, score=-0.099 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=250;, score=0.021 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=250;, score=-0.082 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=500;, score=0.053 total time=   2.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=auto, n_estimators=500;, score=-0.048 total time=   2.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.002 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.106 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.001 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=125;, score=-0.103 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.014 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=250;, score=-0.089 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.040 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=sqrt, n_estimators=500;, score=-0.060 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=100;, score=-0.003 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=100;, score=-0.107 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=125;, score=-0.000 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=125;, score=-0.104 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=250;, score=0.013 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=250;, score=-0.090 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=500;, score=0.037 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=huber, max_features=log2, n_estimators=500;, score=-0.063 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=100;, score=-2.095 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=100;, score=-1.085 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=125;, score=-2.089 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=125;, score=-1.080 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=250;, score=-2.057 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=250;, score=-1.057 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.997 total time=   1.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.013 total time=   1.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-2.097 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.087 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-2.090 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.083 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-2.062 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.062 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-2.004 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.020 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=100;, score=-2.097 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=100;, score=-1.087 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=125;, score=-2.091 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=125;, score=-1.083 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=250;, score=-2.062 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=250;, score=-1.062 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=500;, score=-2.005 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=0.0001, loss=quantile, max_features=log2, n_estimators=500;, score=-1.022 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=100;, score=-0.011 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=100;, score=-0.011 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=125;, score=-0.010 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=125;, score=-0.010 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=250;, score=-0.009 total time=   0.6s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=250;, score=-0.008 total time=   0.6s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=500;, score=-0.005 total time=   1.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=auto, n_estimators=500;, score=-0.005 total time=   1.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=125;, score=-0.011 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=125;, score=-0.011 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=500;, score=-0.006 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=sqrt, n_estimators=500;, score=-0.007 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=100;, score=-0.011 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=125;, score=-0.011 total time=   0.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=125;, score=-0.011 total time=   0.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=250;, score=-0.009 total time=   0.1s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=500;, score=-0.007 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=ls, max_features=log2, n_estimators=500;, score=-0.007 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=100;, score=-0.012 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=100;, score=-0.117 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=125;, score=-0.012 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=125;, score=-0.117 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=250;, score=-0.011 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=250;, score=-0.116 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=500;, score=-0.009 total time=   1.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=auto, n_estimators=500;, score=-0.114 total time=   1.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=250;, score=-0.011 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=250;, score=-0.116 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=500;, score=-0.009 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=sqrt, n_estimators=500;, score=-0.114 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=125;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=125;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=250;, score=-0.011 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=250;, score=-0.116 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=500;, score=-0.009 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=lad, max_features=log2, n_estimators=500;, score=-0.114 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=100;, score=-0.012 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=100;, score=-0.116 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=125;, score=-0.011 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=125;, score=-0.116 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=250;, score=-0.009 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=250;, score=-0.114 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=500;, score=-0.006 total time=   2.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=auto, n_estimators=500;, score=-0.110 total time=   2.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=125;, score=-0.012 total time=   0.3s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=125;, score=-0.116 total time=   0.3s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=250;, score=-0.010 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=250;, score=-0.115 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=500;, score=-0.007 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=sqrt, n_estimators=500;, score=-0.112 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=100;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=100;, score=-0.117 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=125;, score=-0.012 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=125;, score=-0.116 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=250;, score=-0.010 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=250;, score=-0.115 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=500;, score=-0.008 total time=   1.0s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=huber, max_features=log2, n_estimators=500;, score=-0.112 total time=   1.0s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=100;, score=-2.118 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=100;, score=-1.102 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=125;, score=-2.117 total time=   0.5s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=125;, score=-1.101 total time=   0.5s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=250;, score=-2.114 total time=   0.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=250;, score=-1.099 total time=   0.9s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=500;, score=-2.108 total time=   1.9s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=auto, n_estimators=500;, score=-1.094 total time=   1.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=100;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=125;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=250;, score=-2.115 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.100 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=500;, score=-2.109 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.095 total time=   0.8s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=100;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=100;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=125;, score=-2.118 total time=   0.2s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=125;, score=-1.102 total time=   0.2s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=250;, score=-2.115 total time=   0.4s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=250;, score=-1.100 total time=   0.4s\n",
      "[CV 1/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=500;, score=-2.109 total time=   0.8s\n",
      "[CV 2/2] END criterion=mse, learning_rate=1e-05, loss=quantile, max_features=log2, n_estimators=500;, score=-1.096 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=100;, score=0.851 total time=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=100;, score=0.908 total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=125;, score=0.850 total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=125;, score=0.907 total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=250;, score=0.844 total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=250;, score=0.910 total time=  18.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=500;, score=0.856 total time=  36.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=auto, n_estimators=500;, score=0.910 total time=  36.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=100;, score=0.851 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=100;, score=0.906 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=125;, score=0.846 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=125;, score=0.903 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=250;, score=0.855 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=250;, score=0.911 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=500;, score=0.847 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=sqrt, n_estimators=500;, score=0.899 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=100;, score=0.839 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=100;, score=0.892 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=125;, score=0.822 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=125;, score=0.902 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=250;, score=0.848 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=250;, score=0.894 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=500;, score=0.849 total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=ls, max_features=log2, n_estimators=500;, score=0.913 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=100;, score=0.745 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=100;, score=0.759 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=125;, score=0.788 total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=125;, score=0.787 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=250;, score=0.839 total time=  12.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=250;, score=0.863 total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=500;, score=0.841 total time=  24.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=auto, n_estimators=500;, score=0.884 total time=  24.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=100;, score=0.801 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=100;, score=0.803 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=125;, score=0.801 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=125;, score=0.836 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=250;, score=0.832 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=250;, score=0.865 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=500;, score=0.848 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=sqrt, n_estimators=500;, score=0.883 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=100;, score=0.755 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=100;, score=0.781 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=125;, score=0.792 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=125;, score=0.828 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=250;, score=0.823 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=250;, score=0.874 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=500;, score=0.840 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=lad, max_features=log2, n_estimators=500;, score=0.884 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=100;, score=0.846 total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=100;, score=0.905 total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=125;, score=0.843 total time=   9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=125;, score=0.908 total time=   9.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=250;, score=0.846 total time=  18.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=250;, score=0.912 total time=  18.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=500;, score=0.841 total time=  37.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=auto, n_estimators=500;, score=0.916 total time=  36.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=100;, score=0.850 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=100;, score=0.898 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=125;, score=0.841 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=125;, score=0.903 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=250;, score=0.850 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=250;, score=0.891 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=500;, score=0.843 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=sqrt, n_estimators=500;, score=0.908 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=100;, score=0.847 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=100;, score=0.892 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=125;, score=0.849 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=125;, score=0.899 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=250;, score=0.841 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=250;, score=0.907 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=500;, score=0.849 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=huber, max_features=log2, n_estimators=500;, score=0.911 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=100;, score=0.258 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=100;, score=0.042 total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=125;, score=0.238 total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=125;, score=0.187 total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=250;, score=0.558 total time=  11.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=250;, score=-0.257 total time=  11.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=500;, score=0.469 total time=  23.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=auto, n_estimators=500;, score=-0.073 total time=  23.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=100;, score=0.508 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=100;, score=0.541 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.504 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=125;, score=0.591 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.634 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=250;, score=0.728 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.675 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.794 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=100;, score=0.467 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=100;, score=0.676 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=125;, score=0.496 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=125;, score=0.656 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=250;, score=0.651 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=250;, score=0.792 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=500;, score=0.692 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.1, loss=quantile, max_features=log2, n_estimators=500;, score=0.796 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=100;, score=0.611 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=100;, score=0.637 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=125;, score=0.668 total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=125;, score=0.699 total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=250;, score=0.801 total time=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=250;, score=0.836 total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=500;, score=0.841 total time=  30.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=auto, n_estimators=500;, score=0.892 total time=  30.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=100;, score=0.578 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=100;, score=0.563 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=125;, score=0.643 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=125;, score=0.632 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=250;, score=0.787 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=250;, score=0.797 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=500;, score=0.845 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=sqrt, n_estimators=500;, score=0.880 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=100;, score=0.566 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=100;, score=0.544 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=125;, score=0.621 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=125;, score=0.619 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=250;, score=0.782 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=250;, score=0.790 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=500;, score=0.838 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=ls, max_features=log2, n_estimators=500;, score=0.879 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=100;, score=0.415 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=100;, score=0.359 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=125;, score=0.462 total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=125;, score=0.415 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=250;, score=0.602 total time=  11.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=250;, score=0.548 total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=500;, score=0.702 total time=  23.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=auto, n_estimators=500;, score=0.630 total time=  23.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=100;, score=0.396 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=100;, score=0.311 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=125;, score=0.453 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=125;, score=0.370 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=250;, score=0.615 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=250;, score=0.536 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=500;, score=0.716 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=sqrt, n_estimators=500;, score=0.673 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=100;, score=0.395 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=100;, score=0.297 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=125;, score=0.444 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=125;, score=0.364 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=250;, score=0.610 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=250;, score=0.537 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=500;, score=0.716 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=lad, max_features=log2, n_estimators=500;, score=0.681 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=100;, score=0.613 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=100;, score=0.607 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=125;, score=0.666 total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=125;, score=0.675 total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=250;, score=0.792 total time=  14.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=250;, score=0.823 total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=500;, score=0.840 total time=  32.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=auto, n_estimators=500;, score=0.892 total time=  31.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=100;, score=0.573 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=100;, score=0.552 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=125;, score=0.634 total time=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=125;, score=0.624 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=250;, score=0.778 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=250;, score=0.795 total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=500;, score=0.844 total time=   4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=sqrt, n_estimators=500;, score=0.874 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=100;, score=0.568 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=100;, score=0.529 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=125;, score=0.623 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=125;, score=0.607 total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=250;, score=0.767 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=250;, score=0.784 total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=500;, score=0.843 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=huber, max_features=log2, n_estimators=500;, score=0.870 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=100;, score=-1.390 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=100;, score=-0.654 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=125;, score=-1.348 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=125;, score=-0.634 total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=250;, score=-0.963 total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=250;, score=-0.605 total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=500;, score=-0.368 total time=  23.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=auto, n_estimators=500;, score=-0.493 total time=  23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.162 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.553 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.059 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=125;, score=-0.429 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=250;, score=-0.620 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=250;, score=-0.191 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.058 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=sqrt, n_estimators=500;, score=0.266 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=100;, score=-1.132 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=100;, score=-0.504 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=125;, score=-1.032 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=125;, score=-0.420 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=250;, score=-0.509 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=250;, score=-0.089 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=500;, score=0.097 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.01, loss=quantile, max_features=log2, n_estimators=500;, score=0.324 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=100;, score=0.106 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=100;, score=0.110 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=125;, score=0.132 total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=125;, score=0.136 total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=250;, score=0.248 total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=250;, score=0.249 total time=  13.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=500;, score=0.415 total time=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=auto, n_estimators=500;, score=0.421 total time=  27.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=100;, score=0.089 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=100;, score=0.082 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.109 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.105 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.215 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.205 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.378 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.365 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=100;, score=0.087 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=100;, score=0.078 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=125;, score=0.106 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=125;, score=0.098 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=250;, score=0.203 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=250;, score=0.194 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=500;, score=0.360 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=ls, max_features=log2, n_estimators=500;, score=0.347 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=100;, score=0.062 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=100;, score=-0.050 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=125;, score=0.078 total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=125;, score=-0.034 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=250;, score=0.150 total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=250;, score=0.040 total time=  10.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=500;, score=0.266 total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=auto, n_estimators=500;, score=0.177 total time=  21.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=100;, score=0.052 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=100;, score=-0.054 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=125;, score=0.067 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=125;, score=-0.039 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.133 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=250;, score=0.029 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.246 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=sqrt, n_estimators=500;, score=0.138 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=100;, score=0.050 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=100;, score=-0.055 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=125;, score=0.063 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=125;, score=-0.040 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=250;, score=0.128 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=250;, score=0.025 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=500;, score=0.239 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=lad, max_features=log2, n_estimators=500;, score=0.136 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=100;, score=0.111 total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=100;, score=0.015 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=125;, score=0.138 total time=   6.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=125;, score=0.045 total time=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=250;, score=0.256 total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=250;, score=0.173 total time=  14.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=500;, score=0.422 total time=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=auto, n_estimators=500;, score=0.375 total time=  28.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=100;, score=0.090 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=100;, score=-0.005 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.114 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=125;, score=0.018 total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.218 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=250;, score=0.136 total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.380 total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=sqrt, n_estimators=500;, score=0.319 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=100;, score=0.085 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=100;, score=-0.012 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=125;, score=0.107 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=125;, score=0.014 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=250;, score=0.210 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=250;, score=0.126 total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=500;, score=0.364 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=huber, max_features=log2, n_estimators=500;, score=0.303 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=100;, score=-1.928 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=100;, score=-0.991 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=125;, score=-1.884 total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=125;, score=-0.968 total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=250;, score=-1.731 total time=  10.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=250;, score=-0.884 total time=  11.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=500;, score=-1.546 total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=auto, n_estimators=500;, score=-0.754 total time=  22.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-1.976 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=100;, score=-0.997 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-1.942 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=125;, score=-0.973 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-1.792 total time=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=250;, score=-0.878 total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-1.545 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=sqrt, n_estimators=500;, score=-0.720 total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=100;, score=-1.970 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=100;, score=-1.003 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=125;, score=-1.949 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=125;, score=-0.987 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=250;, score=-1.774 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=250;, score=-0.884 total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=500;, score=-1.557 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.001, loss=quantile, max_features=log2, n_estimators=500;, score=-0.728 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=100;, score=0.001 total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=100;, score=0.001 total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=125;, score=0.004 total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=125;, score=0.004 total time=   7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=250;, score=0.019 total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=250;, score=0.021 total time=  13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=500;, score=0.050 total time=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=auto, n_estimators=500;, score=0.053 total time=  28.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.002 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=100;, score=-0.002 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.001 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=125;, score=0.000 total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.014 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=250;, score=0.013 total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.040 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=sqrt, n_estimators=500;, score=0.037 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=100;, score=-0.002 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=100;, score=-0.002 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=125;, score=0.000 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=125;, score=-0.001 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=250;, score=0.013 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=250;, score=0.011 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=500;, score=0.037 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2] END criterion=mae, learning_rate=0.0001, loss=ls, max_features=log2, n_estimators=500;, score=0.034 total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2] END criterion=mae, learning_rate=0.0001, loss=lad, max_features=auto, n_estimators=100;, score=-0.005 total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/indika/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_gb.py:1633: FutureWarning: criterion='mae' was deprecated in version 0.24 and will be removed in version 1.1 (renaming of 0.26). The correct way of minimizing the absolute error is to use  loss='lad' instead.\n",
      "  \" loss='lad' instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search = {\n",
    "    'loss':['ls','lad','huber','quantile'],\n",
    "    'learning_rate':[0.1,0.01,0.001,0.0001,0.00001],\n",
    "    'n_estimators':[100,125,250,500],\n",
    "    'criterion':['friedman_mse','mse','mae'],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    \n",
    "}\n",
    "model = GridSearchCV(GradientBoostingRegressor(),verbose=5,cv=2,param_grid=grid_search)\n",
    "model = train(model,X_train,X_test,y_train,y_test,'GirdSearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e40eee-18ae-419f-b0c0-a3b08b4d5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
